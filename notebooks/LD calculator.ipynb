{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code integrates into the exisiting Open Targets pipeline. It calculates 2 things, Firstly, pairwise LD between a list of SNP ids calculated from indexed 1000 genomes BCF files. Secondly, pairwise LD within a window around a specified SNP. This module currently takes approximately 15 seconds in the current pipeline but by using $\\texttt{tabix}$ to regionally index the files, the necessary SNPs can be extracted much more quickly with $\\texttt{bcftools}$. Both functions now complete in a wall time of $<0.5$s. I use the ENSEMBL API to lookup SNP regions, and then tabix and bcftools to extract out the necessary SNPs. Finally, I use $\\texttt{plink2}$ to efficiently calculate linkage disequilibium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import requests\n",
    "import pdb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_region(SNP_ids):\n",
    "    \"\"\"\n",
    "    Given a list SNPs id, extract the region that encompassed them all from the ENSEMBL REST API.\n",
    "    Advised only for small SNP set sizes < 10.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Extract list of SNP locations from ENSEMBL REST API\n",
    "    SNP_json = json.dumps({\"ids\": SNP_ids})\n",
    "    server = \"http://rest.ensembl.org\"\n",
    "    ext = \"/variation/homo_sapiens\"\n",
    "    headers={ \"Content-Type\" : \"application/json\", \"Accept\" : \"application/json\"}\n",
    "    r = requests.post(server+ext, headers=headers, data=SNP_json)\n",
    "\n",
    "    if not r.ok:\n",
    "        print \"Regions of one of more SNPs could not be retieved\"\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    decoded = r.json()\n",
    "\n",
    "    ### Return the union of all regions.\n",
    "    sorted_locations = sorted([decoded[k]['mappings'][0]['location'] for k in decoded.keys()])\n",
    "    region = '-'.join([sorted_locations[0].split('-')[0],sorted_locations[-1].split('-')[1]])\n",
    "\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_LD_window(SNP_id, window_size,db=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a SNP id, calculate the pairwise LD between all SNPs within window_size base pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Get the SNP location from ENSEMBL\n",
    "    loc = get_region([SNP_id])\n",
    "\n",
    "    ### Define the necessary region.\n",
    "    from_pos = int(loc.split(\":\")[1].split('-')[0]) - (window_size / 2)\n",
    "    to_pos = int(loc.split(\":\")[1].split('-')[1]) + (window_size / 2)\n",
    "    chromosome = loc.split(':')[0]\n",
    "    region = '{}:{}-{}'.format(chromosome,from_pos,to_pos)\n",
    "    \n",
    "    ### Extract this region out from the 1000 genomes BCF\n",
    "    extract_region_comm = \"bcftools view -r {} ../data/processed/CEPH.chr{}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nodup.bcf.gz -O v -o region.vcf\".format(region,chromosome)\n",
    "    subprocess.call(extract_region_comm.split(\" \"))\n",
    "    region_file = open('region.vcf','r')\n",
    "    region_vcf = region_file.read()\n",
    "    \n",
    "\n",
    "    ### Find the order of SNPs in the VCF\n",
    "    SNPs_order = re.findall('rs[0-9]+', region_vcf)\n",
    "    \n",
    "\n",
    "    ### Calculate the pairwise LD using plink2\n",
    "    plinkcomm = \"plink2 --vcf region.vcf --r square --out LDwindow\"\n",
    "    plinkcomm_list = plinkcomm.split(\" \")\n",
    "    subprocess.call(plinkcomm_list)\n",
    "    \n",
    "    ### Remove intermediate region VCF file\n",
    "    if db != 1:\n",
    "        subprocess.call(['rm', 'region.vcf'])\n",
    "    \n",
    "    LD_file = open('LDwindow.ld','r')\n",
    "    g = LD_file.read()\n",
    "    LD_array = [x.split('\\t') for x in g.splitlines()]\n",
    "    LD_file.close\n",
    "    \n",
    "    ### Remove intermediate LD file\n",
    "    if db != 1:\n",
    "        subprocess.call(['rm', 'LDwindow.ld', 'LDwindow.log', 'LDwindow.nosex', 'out.log'])\n",
    "    \n",
    "    return SNPs_order, LD_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 ms, sys: 14.8 ms, total: 26 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = calculate_LD_window('rs74509095', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_pairwise_LD(SNPs_filepath=None,SNP_ids=None, region=None,db=0):\n",
    "    \"\"\"\n",
    "    For large numbers of SNPs, best to specify SNP region with chrom:to-from, e.g. 1:7654947-8155562\n",
    "    For small numbers (<10), regions are extracted from ENSEMBL REST API.\n",
    "    SNPs can be inputted in a list or from a file with one SNP id per line.\n",
    "    \"\"\"\n",
    "\n",
    "    assert SNPs_filepath or SNP_ids, \"SNPs must be inputted either from a file or a list\"\n",
    "    \n",
    "    ### If a SNP file is provided, use it. Otherwise continue with the provided SNP ids.\n",
    "    if SNPs_filepath:\n",
    "        SNPs_file = open(SNPs_filepath, 'r')\n",
    "        SNP_ids = SNPs_file.read().splitlines()\n",
    "        SNPs_file.close()\n",
    "\n",
    "    \n",
    "\n",
    "    ### If a region is not specified, extract it using ENSEMBL REST API. If large amount of SNPs, manually specify this region.\n",
    "    if not region: \n",
    "        region = get_region(SNP_ids)\n",
    "    \n",
    "    if db != 1:\n",
    "        print region\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    ### Extract the required region from the VCF\n",
    "    chromosome = region.split(':')[0]\n",
    "    extract_region_comm = \"bcftools view -r {} ../data/processed/CEPH.chr{}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nodup.bcf.gz -O z -o region.vcf.gz\".format(region,chromosome)\n",
    "    subprocess.call(extract_region_comm.split(\" \"))\n",
    "    region_file = \"region.vcf.gz\"\n",
    "    \n",
    "    \n",
    "    ### Extract the list of SNP ids from this region\n",
    "    vcfcomm = \"vcftools --gzvcf {} --snps {} --recode --stdout\".format(region_file, SNPs_filepath)\n",
    "    vcf = subprocess.check_output(vcfcomm.split(\" \"))\n",
    "    \n",
    "    ### Remove intermediate region VCF file\n",
    "    if db != 1:\n",
    "        subprocess.call(['rm', 'region.vcf.gz'])\n",
    "\n",
    "\n",
    "    f = open('snps.vcf', 'w')\n",
    "    f.write(vcf)\n",
    "    f.close()\n",
    "    \n",
    "    ### Extract out the order of SNPs\n",
    "    SNPs_order = re.findall('rs[0-9]+', vcf)\n",
    "    \n",
    "    ### Use plink2 to calculate pairwise LD between these SNPs.\n",
    "    plinkcomm = \"plink2 --vcf snps.vcf --r square --out LD\"\n",
    "    plinkcomm_list = plinkcomm.split(\" \")\n",
    "    subprocess.call(plinkcomm_list)\n",
    "\n",
    "    ### Remove intermediate SNPs VCF file\n",
    "    if db != 1:\n",
    "        subprocess.call(['rm', 'snps.vcf'])\n",
    "    \n",
    "    ### Read from the generated results file and output an array.\n",
    "    LD_file = open('LD.ld','r')\n",
    "    g = LD_file.read()\n",
    "    LD_array = [x.split('\\t') for x in g.splitlines()]\n",
    "    LD_file.close\n",
    "    \n",
    "    ### Remove intermediate LD \n",
    "    if db != 1:\n",
    "        subprocess.call(['rm', 'LD.ld', 'LD.log', 'LD.nosex', 'out.log'])\n",
    "    \n",
    "    return (SNPs_order, LD_array)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:7637119-7968778\n",
      "CPU times: user 4.25 ms, sys: 13 ms, total: 17.2 ms\n",
      "Wall time: 431 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['rs6661496',\n",
       "  'rs79544751',\n",
       "  'rs148043253',\n",
       "  'rs74509095',\n",
       "  'rs4908705',\n",
       "  'rs4908708'],\n",
       " [['1', '1', '-0.0256579', '-0.0413742', '-0.0729325', '-0.0729325'],\n",
       "  ['1', '1', '-0.0256579', '-0.0413742', '-0.0729325', '-0.0729325'],\n",
       "  ['-0.0256579', '-0.0256579', '1', '0.325107', '0.248882', '0.248882'],\n",
       "  ['-0.0413742', '-0.0413742', '0.325107', '1', '-0.0778898', '-0.0778898'],\n",
       "  ['-0.0729325', '-0.0729325', '0.248882', '-0.0778898', '1', '1'],\n",
       "  ['-0.0729325', '-0.0729325', '0.248882', '-0.0778898', '1', '1']])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time calculate_pairwise_LD(\"../data/raw/smallrsIDs.txt\", db=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
